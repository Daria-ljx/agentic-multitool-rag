# ğŸ§  Multi-Tool Agentic RAG System

### *(LangGraph Â· LangChain Â· Tavily Â· FAISS Â· FastAPI Â· Streamlit Â· LangSmith)*

A **production-oriented Agentic AI system** built with **LangGraph** and **LangChain**, featuring **multi-tool orchestration**, **RAG**, **web search via Tavily**, **summarization**, **self-reflection**, **conversation memory**, and **full observability**.

This project demonstrates how an LLM can **reason about user intent, select tools dynamically, and coordinate multiple tools** within an explicit, debuggable agent workflow.

---

## âœ¨ Key Features

### ğŸ” Multi-Tool Agent Orchestration

The agent does **not blindly call all tools**.
Instead, an **LLM-based Router Agent** decides:

* which tools are needed
* in what order they should be executed
* whether summarization is required

Supported tools:

* **RAG Tool** â€“ internal document retrieval using FAISS
* **Web Search Tool (Tavily)** â€“ reliable external knowledge augmentation
* **Summarizer Tool** â€“ condenses long contexts
* **LLM Reasoning Tool** â€“ final answer generation

---

### ğŸ§© Multi-Agent Workflow (LangGraph)

The system is implemented as an explicit **LangGraph state machine**, where each node has a single responsibility:

* **Router Agent** â€“ intent analysis & tool selection
* **RAG Agent** â€“ internal document retrieval
* **Web Agent (Tavily)** â€“ external knowledge search
* **Summarizer Agent** â€“ context compression
* **Answer Agent** â€“ draft response generation
* **Critic Agent** â€“ hallucination & gap detection
* **Refiner Agent** â€“ answer improvement
* **Memory Agent** â€“ conversation state update

This design makes the agent **interpretable, controllable, and production-ready**.

---

## ğŸ–¥ï¸ Streamlit UI Demo

The project includes a **ChatGPT-style Streamlit interface** with clear separation of **user and assistant messages**, supporting multi-turn conversations and optional debugging panels.

### Features:

* Distinct chat bubbles for user and assistant
* Conversation memory across turns
* Real-time agent execution feedback

ğŸ“¸ **Streamlit Screenshot**

![Streamlit UI](images/streamlit_demo.png)

---

## ğŸ” Observability & Debugging (Three Layers)

This project emphasizes **observability**, which is critical for real-world Agent systems.

### 1ï¸âƒ£ Console Logging

Structured logging is enabled across all agent nodes:

* Router decisions
* Tool execution
* Error handling and fallbacks

Example:

```text
[INFO] [src.agent.run_agent] [run_agent] query=What does this internal document discuss?
[INFO] [src.agent.nodes] [Router] raw=["rag"]
[INFO] [src.agent.nodes] [RAG] running rag_search
[INFO] [src.agent.nodes] [Answer] generating draft
[INFO] [src.agent.nodes] [Critic] critiquing draft
[INFO] [src.agent.nodes] [Refine] refining answer
```

---

### 2ï¸âƒ£ Streamlit Visual Debugging

Within the Streamlit app:

* Tool plans can be expanded and inspected
* Agent behavior can be observed interactively
* Errors are surfaced clearly without crashing the app

---

### 3ï¸âƒ£ LangSmith Tracing

The entire agent workflow is traced using **LangSmith**, providing:

* Full node-level execution traces
* Inputs / outputs per agent step
* Prompt inspection
* Latency and token usage analysis

ğŸ“¸ **LangSmith Trace Screenshot**

![LangSmith Trace](images/langsmith.png)

---

## ğŸ§  Agent Workflow (Simplified View)

Below is a **logic-level view** of the agent workflow (abstracted from execution details):

```mermaid
flowchart TD
    router[Router]

    rag[RAG Retrieval]
    web[Web Search]
    merge[Merge Context]
    summarize[Summarize Context]
    draft[Generate Draft]
    critic[Critic]
    refine[Refine Answer]
    memory[Update Memory]

    %% Entry
    router -->|needs_rag| rag
    router -->|needs_web| web

    %% Conditional routing
    rag -->|needs_web| web
    rag -->|else| merge
    web --> merge

    %% Post-processing
    merge -->|needs_summarize| summarize
    merge -->|else| draft
    summarize --> draft

    %% Self-critique loop
    draft --> critic
    critic --> refine
    refine --> memory

```

---

## ğŸ—‚ Project Structure

```text
src/
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ graph_state.py      # TypedDict state definition
â”‚   â”œâ”€â”€ prompts.py          # Prompts for router, answer, critic, refiner
â”‚   â”œâ”€â”€ nodes.py            # Agent nodes (router, rag, web, summarize, etc.)
â”‚   â”œâ”€â”€ rag_graph.py        # LangGraph workflow definition
â”‚   â””â”€â”€ run_agent.py        # High-level agent execution API
â”‚
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ retriever_tool.py   # FAISS-based RAG tool
â”‚   â”œâ”€â”€ web_search_tool.py  # Tavily web search tool
â”‚   â””â”€â”€ summarizer_tool.py  # LLM-based summarization tool
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€raw /                # Original documents
â”‚   â”œâ”€â”€ clean_text.py      
â”‚   â””â”€â”€ load_docs.py
|
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ (faiss_store)/        # FAISS vector store files
â”‚   â”œâ”€â”€ build_vectorstore.py      
â”‚   â””â”€â”€ embeddings.py
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ constants.py
â”‚   â””â”€â”€ logger.py
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ fastapi_app.py      # REST API service
â”‚   â””â”€â”€ streamlit_app.py    # Chat-style UI
â”‚
â”œâ”€â”€ main.py                 # CLI entry point
â””â”€â”€ requirements.txt
```

---

## ğŸš€ How to Run

### 1ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

### 2ï¸âƒ£ Environment Variables (`.env`)

```env
OPENAI_API_KEY=your_api_key

# Tavily Web Search
TAVILY_API_KEY=your_tavily_key

# LangSmith Observability
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=your_langsmith_key
LANGCHAIN_PROJECT=MultiTool-Agentic-RAG
```

---

### 3ï¸âƒ£ Run FastAPI Backend

```bash
uvicorn src.app.fastapi_app:app --reload
```

---

### 4ï¸âƒ£ Run Streamlit UI

```bash
streamlit run src/app/streamlit_app.py
```


---

## ğŸ“Œ Assets Directory

```text
assets/
â”œâ”€â”€ streamlit_demo.png
â””â”€â”€ langsmith_trace.png
```
